<!DOCTYPE HTML>
<html lang="en">


<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="ISLR_ch4.4 Linear_Discriminant_Analysis, Naixin&#39;s blog">
    <meta name="baidu-site-verification" content>
    <meta name="google-site-verification" content>
    <meta name="360-site-verification" content>
    <meta name="description" content="ISLR_ch4.4 Linear_Discriminant_AnalysisLDA V.S. Logistic Regression:

When the classes are well-separated, the parameter">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>ISLR_ch4.4 Linear_Discriminant_Analysis | Naixin&#39;s blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    <style type="text/css">
        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body>

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Naixin's blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <span>Home</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <span>Learning notes</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <span>About</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <span>Courses</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <span>Contact</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="Search"></i>
        </a>
    </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Naixin's blog</div>
        <div class="logo-desc">
            
            You never lose, you either win or learn.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                Home
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                Learning notes
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                About
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                Courses
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-link"></i>
                
                Contact
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/naixinzhang" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/naixinzhang" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/24.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        ISLR_ch4.4 Linear_Discriminant_Analysis
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                        <a href="/tags/Machine-Learning-notes/" target="_blank">
                            <span class="chip bg-color">Machine Learning notes</span>
                        </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                        <a href="/categories/An-Introduction-to-statistical-Learning/" class="post-category" target="_blank">
                            An Introduction to statistical Learning
                        </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2019-09-23
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>Author:&nbsp;&nbsp;
                    
                    Naixin Zhang
                    
                </div>

                
                
                <div class="info-break-policy">
                    <i class="fa fa-file-word-o fa-fw"></i>Word Count:&nbsp;&nbsp;
                    2.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="fa fa-clock-o fa-fw"></i>Read Times:&nbsp;&nbsp;
                    13 Min
                </div>
                
                

                
                <div id="busuanzi_container_page_pv" class="info-break-policy">
                    <i class="fa fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                    <span id="busuanzi_value_page_pv"></span>
                </div>
                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="ISLR-ch4-4-Linear-Discriminant-Analysis"><a href="#ISLR-ch4-4-Linear-Discriminant-Analysis" class="headerlink" title="ISLR_ch4.4 Linear_Discriminant_Analysis"></a>ISLR_ch4.4 Linear_Discriminant_Analysis</h1><p><strong>LDA V.S. Logistic Regression</strong>:</p>
<ol>
<li><p>When the classes are well-separated, the parameter estimates for the
logistic regression model are surprisingly unstable. Linear discriminant
analysis does not suffer from this problem.</p>
</li>
<li><p>If n is small and the distribution of the predictors X is approximately
normal in each of the classes, the linear discriminant model is again
more stable than the logistic regression model.</p>
</li>
<li><p>Linear discriminant analysis is popular
when we have more than two response classes.</p>
</li>
</ol>
<h1 id="Using-Bayes’-Theorem-for-Classification"><a href="#Using-Bayes’-Theorem-for-Classification" class="headerlink" title="Using Bayes’ Theorem for Classification"></a>Using Bayes’ Theorem for Classification</h1><p>Suppose that we wish to classify an observation into one of K classes, where
K ≥ 2.</p>
<p><strong>Prior</strong>:Let $\pi_k=Pr(Y=k)$ represent the overall or <strong><em>prior</em></strong>
probability that a randomly chosen observation comes from the kth class. This is the probability that a given observation is associated with the kth
category of the response variable Y . </p>
<p>Let $f_k(X) ≡ Pr(X = x|Y = k)$ denote
the <strong><em>density function</em></strong> of X for an observation that comes from the kth class. In other words, fk(x) is relatively large if there is a high probability that an observation in the kth class has X ≈ x.</p>
<p><strong>Bayes’
theorem</strong> states that</p>
<p>\begin{align}
Pr(Y=k|X=x)=\frac{\pi_k f_k(x)}{\sum_{l=1}^K\pi_lf_l(x)} 
\end{align}</p>
<p><strong>Posterior</strong>:$p_k(X)
= Pr(Y = k|X)$ an observation X = x belongs to the kth class, given the predictor value for that
observation</p>
<p><strong>Estimating $π_k$:</strong> simply compute the fraction of the training
observations that belong to the kth class.</p>
<p><strong>Estimating $f_k(X)$:</strong> more challenging</p>
<h1 id="Linear-Discriminant-Analysis-for-p-1"><a href="#Linear-Discriminant-Analysis-for-p-1" class="headerlink" title="Linear Discriminant Analysis for p = 1"></a>Linear Discriminant Analysis for p = 1</h1><p>Assume p = 1—that is, we have only one predictor. We
would like to obtain an estimate for $f_k(x)$ that we can estimate $p_k(x)$. We will then classify an observation to the class
for which $p_k(x)$ is greatest. </p>
<h2 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h2><p>In order to estimate $f_k(x)$, we will first make
some assumptions about its form:</p>
<ol>
<li>Assume that $f_k(x)$ is normal or Gaussian.
\begin{align}
f_k(x)=\frac{1}{\sqrt{2\pi}\sigma_k}\exp{\left( -\frac{1}{2\sigma_k^2}(x-\mu_k)^2 \right)}
\end{align}</li>
</ol>
<p>where $μ_k$ and $σ_k^2$ are the mean and variance parameters for the kth class.</p>
<ol start="2">
<li>Assume that $\sigma_1^2=…=\sigma_k^2$
: that is, there is a shared
variance term across all K classes, which for simplicity we can denote by
$\sigma^2$.</li>
</ol>
<p>So
\begin{align}
p_k(x)=\frac{\pi_k \frac{1}{\sqrt{2\pi}\sigma}\exp{\left( -\frac{1}{2\sigma^2}(x-\mu_k)^2 \right)}}{\sum_{l=1}^K\pi_l\frac{1}{\sqrt{2\pi}\sigma}\exp{\left( -\frac{1}{2\sigma^2}(x-\mu_l)^2 \right)}}
\end{align}</p>
<p>The <strong>Bayes classifier</strong> involves assigning an observation X = x to the class for which $p_k(x)$ is largest. Taking the log of $p_k(x)$
and rearranging the terms, it is not hard to show that this is equivalent to
assigning the observation to the class for which</p>
<p>\begin{align}
\delta_k(x)=x\frac{\mu_k}{\sigma^2}-\frac{\mu_k^2}{2\sigma^2}+\log(\pi_k) \quad\quad (4.13)
\end{align}</p>
<p>is largest.</p>
<p>For instance, if K = 2 and π1 = π2, then the Bayes classifier
assigns an observation to class 1 if $2x (μ_1 − μ_2) &gt; μ^2_1
− μ^2_2$, and to class
2 otherwise. In this case, the Bayes decision boundary corresponds to the
point where</p>
<p>\begin{align}
x=\frac{\mu_1^2-\mu_2^2}{2(\mu_1-\mu_2)}=\frac{\mu_1+\mu_2}{2}
\end{align}</p>
<h2 id="Parameters-Estimation"><a href="#Parameters-Estimation" class="headerlink" title="Parameters Estimation"></a>Parameters Estimation</h2><p>In practice, even if we are quite certain of our assumption that X is drawn
from a Gaussian distribution within each class, we still have to estimate
the parameters $μ_1, . . . , μ_K, π_1, . . . , π_K$, and $σ^2$.</p>
<p><strong>Linear discriminant analysis (LDA)</strong> method approximates the Bayes classifier by plugging estimates for $μ_1, . . . , μ_K, π_1, . . . , π_K$, and $σ^2$ into (4.13)</p>
<p>\begin{align}
\hat{\mu}_k=\frac{1}{n_k}\sum_{i:y_i=k}x_i  \quad (4.15) \<br>\hat{\sigma}^2=\frac{1}{n-K}\sum_{k=1}^K\sum_{i:y_i=k}(x_i-\hat{\mu_k})^2 \quad (4.16)\<br>\hat{\pi_k}=\frac{n_k}{n}
\end{align} </p>
<p>where n is the total number of training observations, and $n_k$ is the number
of training observations in the kth class. </p>
<p>$\hat{\mu}_k$: average of all the training observations from the kth class;</p>
<p>$\hat{\sigma}^2$: a weighted average of the sample variances for each of the K classes.</p>
<p>$\hat{\pi_k}$: the proportion of the training observations
that belong to the kth class</p>
<h2 id="LDA-classifier"><a href="#LDA-classifier" class="headerlink" title="LDA classifier"></a>LDA classifier</h2><p>The LDA classifier assigns an observation X = x to the class for which</p>
<p>\begin{align}
\hat{\delta}_k(x)=x\frac{\hat{\mu}_k}{\hat{\sigma}^2}-\frac{\hat{\mu}_k^2}{2\hat{\sigma}^2}+\log(\hat{\pi}_k)
\end{align} </p>
<p>is largest.</p>
<p>The word <strong><em>linear</em></strong> in the classifier’s name stems from the fact
that the <strong><em>discriminant functions</em></strong> $\hat{\delta}_k(x)$ are linear functions of x.</p>
<img src="./images/6.png" width="600">

<p>The right-hand panel of Figure 4.4 displays a histogram of a random
sample of 20 observations from each class. </p>
<p>To implement LDA,</p>
<ol>
<li>Estimating πk, μk, and σ2 using (4.15) and (4.16).</li>
<li>Compute the decision boundary, shown as a black solid line, that results from assigning an observation to the class for which $\hat{\delta}_k(x)$ is largest.</li>
</ol>
<p>In this case, since n1 = n2 = 20,
we have $\hat{\pi_1}$ = $\hat{\pi_2}$. As a result, the decision boundary corresponds to the
midpoint between the sample means for the two classes,$\frac{\mu_1+\mu_2}{2}$</p>
<h1 id="Linear-Discriminant-Analysis-for-p-gt-1"><a href="#Linear-Discriminant-Analysis-for-p-gt-1" class="headerlink" title="Linear Discriminant Analysis for p &gt;1"></a>Linear Discriminant Analysis for p &gt;1</h1><p>Assume that X = (X1,X2, . . .,Xp) is drawn from a <strong>multivariate Gaussian</strong> (or multivariate normal) distribution, with a class-specific mean vector and a common covariance matrix.</p>
<h2 id="Multivariate-Gaussian-Distribution"><a href="#Multivariate-Gaussian-Distribution" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h2><p>Assumes that each individual predictor
follows a one-dimensional normal distribution with some
correlation between each pair of predictors.</p>
<img src="./images/7.png" width="600">

<p>To indicate that a p-dimensional random variable X has a multivariate
Gaussian distribution, we write X ∼ N(μ,Σ). Here E(X) = μ is
the mean of X (a vector with p components), and Cov(X) = Σ is the
p × p <strong>covariance matrix</strong> of X. Formally, the <strong>multivariate Gaussian density</strong>
is defined as</p>
<p>\begin{align}
f(x)=\frac{1}{\sqrt{(2\pi)^{p}|Σ|}}\exp{\left( \frac{1}{2}(x-\mu)^TΣ^{-1}(x-\mu) \right)}
\end{align} </p>
<p>In the case of p &gt; 1 predictors, the <strong>LDA classifier</strong> assumes that the
observations in the kth class are drawn from a multivariate Gaussian distribution
$N(μ_k,Σ)$, where $μ_k$ is a class-specific mean vector, and Σ is a
covariance matrix that is common to all K classes.</p>
<p>Plugging the density function for the kth class, $f_k(X = x)$, into $Pr(Y = k|X = x)$, the Bayes classifier assigns an observation X = x
to the class for which</p>
<p>\begin{align}
\delta_k(x)=x^TΣ^{-1}\mu_k-\frac{1}{2}\mu_k^TΣ^{-1}\mu_k+\log{\pi_k}  \quad \quad (4.19)
\end{align} </p>
<p>is largest.</p>
<img src="./images/8.png" width="600">

<p>Once again, we need to estimate the unknown parameters $μ_1, . . . , μ_K$,
$π_1, . . . , π_K$, and Σ; the formulas are similar to those used in the one dimensional
case, given in (4.15). To assign a new observation X = x,
<strong>LDA</strong> plugs these estimates into (4.19) and classifies to the class for which
$\hat{\delta}_k(x)$ is largest.</p>
<blockquote>
<p>Overall, the LDA decision boundaries are
pretty close to the Bayes decision boundaries, shown again as dashed lines.</p>
</blockquote>
<h2 id="Caveats"><a href="#Caveats" class="headerlink" title="Caveats"></a>Caveats</h2><ol>
<li><p>Training error rates will usually be lower than test error
rates. The higher the ratio of parameters p to number
of samples n, the more we expect this overfitting to play a role.</p>
</li>
<li><p>Second, since only 3.33% of the individuals in the training sample
defaulted, a simple but useless classifier that always predicts that each individual will not default, regardless of his or her credit card
balance and student status, will result in an error rate of 3.33%. In
other words, the trivial <strong>null classifier</strong> will achieve an error rate that is only a bit higher than the LDA training set error rate.</p>
</li>
</ol>
<h3 id="Two-Types-of-Error-Confusion-Matrix"><a href="#Two-Types-of-Error-Confusion-Matrix" class="headerlink" title="Two Types of Error, Confusion Matrix"></a>Two Types of Error, Confusion Matrix</h3><p>Binary classifier can make two types of
errors:</p>
<ol>
<li>it can incorrectly assign an individual who defaults to the no default
category;</li>
<li>it can incorrectly assign an individual who does not default to
the default category.</li>
</ol>
<p><strong>Confusion Matrix</strong></p>
<p>*注意这张图不是标准的confusion matrix，看下面那张
<img src="./images/10.png" width="600"></p>
<p><strong>Explanation</strong>：
The matrix
table reveals that LDA predicted that a total of 104 people would default.
Of these people, 81 actually defaulted and 23 did not. </p>
<p><strong>Type I Error</strong>： Of the 333 individuals who defaulted, 252 (or 75.7%) were missed by LDA. So while the overall error
rate is low, the error rate among individuals who defaulted is very high.
From the perspective of a credit card company that is trying to identify
high-risk individuals, an error rate of 252/333 = 75.7% among individuals
who default may well be unacceptable.</p>
<p><strong>Type II Error</strong>：Only 23 out
of 9, 667 of the individuals who did not default were incorrectly labeled.
This looks like a pretty low error rate! </p>
<img src="./images/11.png" width="1000">


<p><strong>Sensitivity</strong>:the percentage of
true defaulters that are identified, a low 24.3% in this case.</p>
<p><strong>Specificity</strong>:the percentage of non-defaulters that are correctly identified, here (1 −
23/9, 667)× 100 = 99.8%.</p>
<h3 id="Why-does-LDA-do-such-a-poor-job-of-classifying-the-customers-who-default"><a href="#Why-does-LDA-do-such-a-poor-job-of-classifying-the-customers-who-default" class="headerlink" title="Why does LDA do such a poor job of classifying the customers who default?"></a>Why does LDA do such a poor job of classifying the customers who default?</h3><blockquote>
<p>In other words, why does it have such a low sensitivity? </p>
</blockquote>
<p>LDA is trying to approximate the Bayes classifier, which has the lowest
total error rate out of all classifiers (if the Gaussian model is correct).
That is, the Bayes classifier will yield the smallest possible total number
of misclassified observations, irrespective of which class the errors come
from.</p>
<p>The Bayes classifier works by assigning an observation to the class for
which the posterior probability pk(X) is greatest. In the two-class case, this
amounts to assigning an observation to the default class if $Pr(default = Yes|X = x) &gt; 0.5.$</p>
<p>Thus, the Bayes classifier, and by extension LDA, uses a threshold of 50%
for the posterior probability of default in order to assign an observation
to the default class.</p>
<p><strong>Modify LDA</strong></p>
<p>If we are concerned about incorrectly predicting
the default status for individuals who default, then we can consider
lowering this threshold.</p>
<p>$P(default = Yes|X = x) &gt; 0.2$</p>
<p>Figure 4.7 illustrates the trade-off that results from modifying the threshold
value for the posterior probability of default</p>
<img src="./images/12.png" width="700">

<p>How can we decide which threshold value is
best? Such a decision must be based on <strong>domain knowledge</strong>, such as detailed
information about the costs associated with default.</p>
<h3 id="ROC-amp-AUC"><a href="#ROC-amp-AUC" class="headerlink" title="ROC &amp; AUC"></a>ROC &amp; AUC</h3><p><strong>ROC</strong>:The ROC curve is a popular graphic for simultaneously displaying the
two types of errors for all possible thresholds.</p>
<p><strong>AUC</strong>: The overall performance of a classifier, summarized
over all possible thresholds, is given by the area under the (ROC)
curve (AUC).</p>
<ul>
<li><p>An ideal ROC curve will hug the top left corner, so the larger
the AUC the better the classifier. We expect
a classifier that performs no better than chance to have an AUC of 0.5</p>
</li>
<li><p>ROC curves are useful for comparing different classifiers, since they take
into account all possible thresholds.</p>
</li>
</ul>
<img src="./images/13.png" width="700">



<img src="./images/14.png" width="700">

<img src="./images/15.png" width="700">

<h1 id="Quadratic-Discriminant-Analysis"><a href="#Quadratic-Discriminant-Analysis" class="headerlink" title="Quadratic Discriminant Analysis"></a>Quadratic Discriminant Analysis</h1><p><strong>Quadratic discriminant analysis (QDA)</strong> classifier results from assuming that the
observations from each class are drawn from a Gaussian distribution, and
plugging estimates for the parameters into Bayes’ theorem in order to perform
prediction. </p>
<p>However, unlike LDA, <strong>QDA assumes that each class has
its own covariance matrix</strong>. That is, it assumes that an observation from the
kth class is of the form $X ∼ N(μ_k,Σ_k)$, where $Σ_k$ is a covariance matrix
for the kth class. Under this assumption, the Bayes classifier assigns an
observation $X = x$ to the class for which</p>
<p>\begin{align}
\delta_k(x)&amp;=-\frac{1}{2}(x-\mu_k)^TΣ_k^{-1}(x-\mu_k)-\frac{1}{2}\log{|Σ_k|}+\log{\pi_k} \<br>&amp;=-\frac{1}{2}x^TΣ_k^{-1}x+x^TΣ_k^{-1}\mu_k-\frac{1}{2}\mu_k^TΣ_k^{-1}\mu_k-\frac{1}{2}\log{|Σ_k|}+\log{\pi_k}
\end{align} </p>
<p>is largest.</p>
<p>So the QDA classifier involves plugging estimates for $Σ_k, μ_k, π_k$ into $\delta_k(x)$, and then assigning an observation $X = x$ to the class
for which this quantity is largest. Unlike LDA, the quantity $x$ appears
as a quadratic function.</p>
<h2 id="Why-does-it-matter-whether-or-not-we-assume-that-the-K-classes-share-a-common-covariance-matrix"><a href="#Why-does-it-matter-whether-or-not-we-assume-that-the-K-classes-share-a-common-covariance-matrix" class="headerlink" title="Why does it matter whether or not we assume that the K classes share a common covariance matrix?"></a>Why does it matter whether or not we assume that the K classes share a common covariance matrix?</h2><p>The answer lies in the <strong>bias-variance trade-off</strong>:</p>
<ul>
<li>When there are p predictors, then estimating a covariance matrix requires estimating
p(p+1)/2 parameters. QDA estimates a separate covariance matrix
for each class, for a total of Kp(p+1)/2 parameters.</li>
<li>Consequently, LDA is a much less flexible classifier than QDA, and
so has substantially lower variance. </li>
<li>But there is a trade-off: if LDA’s assumption that
the K classes share a common covariance matrix is badly off, then LDA
can suffer from high bias. </li>
</ul>
<p><strong>Conclusion</strong></p>
<ul>
<li>LDA tends to be a better bet
than QDA if there are relatively few training observations and so reducing
variance is crucial. </li>
<li>QDA is recommended if the training set is
very large, so that the variance of the classifier is not a major concern, or if
the assumption of a common covariance matrix for the K classes is clearly
untenable</li>
</ul>
<img src="./images/16.png" width="700">


<pre class="line-numbers language-python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

            </div>
            <hr />

            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone, qq, weibo, douban"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            


        </div>
    </div>

    
    <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'c090019fe3f06f8ef15d',
        clientSecret: '9f220a5e71efc340544fce7ae397f63151db8747',
        repo: 'naixinzhang.github.io',
        owner: 'naixinzhang',
        admin: "naixinzhang",
        id: '2019/09/23/islr/4.4linear-discriminant-analysis/',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    
    <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<!-- <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script> -->

<script>
    new Valine({
        el: '#vcomments',
        appId: '',
        appKey: '',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'false' === 'true',
        avatar: 'wavatar',
        pageSize: '10',
        lang: 'en',
        placeholder: '如果你没有GitHub账号，还可以在这里评论啦！'
    });
</script>

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2019/09/23/islr/3.3potential-problems/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="ISLR_ch3.3 Potential Problems">
                        
                        <span class="card-title">ISLR_ch3.3 Potential Problems</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ISLR_ch3.3 Potential ProblemsQualitative PredictorsPredictors with Only Two LevelsSuppose that we wish to investigate di
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-23
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/An-Introduction-to-statistical-Learning/" class="post-category" target="_blank">
                                    An Introduction to statistical Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Machine-Learning-notes/" target="_blank">
                        <span class="chip bg-color">Machine Learning notes</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2019/09/23/islr/5.1cross-validation/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="ISLR_ch5.1 Cross_Validation">
                        
                        <span class="card-title">ISLR_ch5.1 Cross_Validation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ISLR_ch5.1 Cross_ValidationResampling methods:involve repeatedly drawing samples from a training set and refitting a mod
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2019-09-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/An-Introduction-to-statistical-Learning/" class="post-category" target="_blank">
                                    An Introduction to statistical Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Machine-Learning-notes/" target="_blank">
                        <span class="chip bg-color">Machine Learning notes</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

    <footer class="page-footer bg-color center-align">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            &copy; 2020 NaixinZhang. All Rights Reserved.
        </div>
    </div>
</footer>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <script type="text/javascript"> var OriginTitile = document.title, st; document.addEventListener("visibilitychange", function () { document.hidden ? (document.title = "Σ(っ °Д °;)っ喔哟，崩溃啦！", clearTimeout(st)) : (document.title = "φ(゜▽゜*)♪咦，又好了！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) })
    </script>

    <!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', '');
</script>



    
    <script src="/libs/others/clicklove.js"></script>
    

    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    <!-- 雪花特效 -->
    

</body>

</html>